Как выбор структуры базы данных (SQL или NoSQL) влияет на дизайн CRUD API? 
Выбор между SQL и NoSQL базой данных заметно влияет на то, как проектируется весь CRUD API. В случае SQL используется строгая схема с фиксированными типами, связями, ограничениями и правилами целостности. Это заставляет API быть более строгим: каждая операция должна соблюдать структуру таблиц, валидировать входные данные, учитывать транзакции и зависимые сущности. Например, когда создаётся заказ, API должен убедиться, что соответствующий пользователь и товар существуют, иначе SQL просто выкинет ошибку. В NoSQL, напротив, структура данных значительно гибче, поэтому API может позволять больше вариаций. Документы в одной коллекции могут иметь разные поля, что создаёт свободу, но одновременно повышает риск беспорядка, если в API нет чёткого контроля структуры. В итоге SQL предполагает более формальный и предсказуемый API, а NoSQL - гибкий, но требующий осторожности.

Какие проблемы могут возникнуть при массовых обновлениях данных через API? 
Когда речь идёт о массовых обновлениях данных через API, всегда есть риск столкнуться с множеством технических и архитектурных проблем. Массовый запрос может перегрузить базу данных, вызвать долгие блокировки таблиц, заставить другие запросы ждать, а иногда даже привести к таймаутам. Это особенно заметно в системах, где обновления затрагивают десятки тысяч строк. Кроме того, массовые операции могут частично выполниться: часть данных обновится, а часть - нет, если не использовать транзакции или если внутри операции произошла ошибка. Это создаёт опасную ситуацию «полуобновлённой» базы, которую потом трудно исправить. Одновременно обновления могут конфликтовать друг с другом, если несколько пользователей выполняют bulk update параллельно.

Почему важно использовать правильные HTTP-методы (GET, POST, PUT, DELETE), а не только POST? 
Использование правильных HTTP-методов - это не просто вопрос стиля, а важный элемент архитектуры API. Если всё реализовывать через POST, то API становится непредсказуемым и плохо совместимым с существующими инструментами и паттернами. Правильное разделение методов делает поведение API понятным: GET безопасен и предназначен только для получения данных, POST — для создания, PUT и PATCH - для изменения, DELETE - для удаления. Когда разработчики нарушают эти принципы, начинаются проблемы с кэшированием, отслеживанием изменений, логированием и взаимодействием между фронтендом и бэкендом. Кроме того, многие библиотеки, прокси, CDN и браузеры ожидают определённого поведения от разных методов, и если всё делается через POST, эти механизмы перестают работать корректно.

Какие уязвимости могут возникнуть при хранении JWT на клиентской стороне? 
При хранении JWT-токенов на клиентской стороне возникает ряд серьёзных уязвимостей. Наиболее опасная - XSS-атака, когда злоумышленник может выполнить JavaScript-код на странице и украсть токен из localStorage или sessionStorage. Такая кража даёт доступ к аккаунту пользователя, пока токен действителен. Ещё один риск - повторное использование токена, когда злой актор может применять украденный токен до его истечения. Проблемы также усиливаются, если токен живёт слишком долго: его можно использовать месяцами после кражи. В случае, если токен хранится в cookies без флага HttpOnly, его также можно получить через XSS. Даже браузерные расширения иногда имеют доступ к хранению данных и могут потенциально прочитать токен.

В каких случаях стоит ограничивать время жизни JWT, и какие проблемы это создаёт для UX? 
Ограничивать время жизни JWT важно в системах, где данные критичны: банковские приложения, админ-панели, сервисы с высокой чувствительностью информации. Короткий срок жизни снижает ущерб от возможной кражи токена, но создаёт трудности для пользователя. Если срок слишком короткий, люди начинают сталкиваться с постоянной повторной авторизацией, неожиданными выходами из системы, потерей введённых данных и прерыванием процессов. Чтобы смягчить эту проблему, обычно используют пару: короткоживущий access token и более длинный refresh token, который позволяет автоматически получать новый токен без явного входа пользователя.

Как логирование помогает в расследовании инцидентов безопасности? 
Логирование играет центральную роль в расследовании инцидентов безопасности. По сути, это цифровой след, который показывает, кто и когда делал запросы, откуда пришёл трафик, какие ошибки происходили, какие действия выполнялись перед проблемой. Если возникает взлом или подозрительная активность, логи - единственный способ понять, что реально произошло. Они позволяют проследить цепочку событий, обнаружить аномалии, сопоставить действия разных сервисов и выяснить, каким образом злоумышленник проник в систему и какие данные затронул. Без логов расследование превращается в угадывание.

В чём разница между горизонтальным и вертикальным масштабированием, и как это связано с кэшированием? 
Вопрос масштабирования также связан с архитектурой API и баз данных. Вертикальное масштабирование означает увеличение ресурсов одного сервера - больше оперативной памяти, процессоров или более быстрые диски. Это просто, но дорого и имеет физические пределы. Горизонтальное масштабирование - это добавление новых серверов, распределение нагрузки между ними. Оно гибче и надёжнее, но требует продуманного управления состоянием и кэшированием. Кэширование особенно важно в горизонтально масштабируемой архитектуре: если каждый сервер будет обращаться к базе данных напрямую без кэша, нагрузка на центральное хранилище станет слишком высокой. Единый Redis-кэш или подобное решение позволяет значительно уменьшить нагрузку и обеспечить согласованность данных между серверами.

Какой риск несут фоновые задачи при сбое очереди сообщений? 
Фоновые задачи и очереди сообщений - это ещё один важный элемент распределённых систем. Если очередь сообщений падает или сбоит, фоновые задачи могут потеряться или наоборот выполниться дважды. Это создаёт опасные ситуации: некоторые операции могут не выполниться полностью, например, уведомления не отправятся, денежная транзакция не подтвердится или обработка файлов остановится. 

Почему важно учитывать идемпотентность задач при их повторном выполнении?
Повторное выполнение задачи также может быть разрушительным, если операция не является идемпотентной. Идемпотентность означает, что повтор одного и того же действия не должен менять результат. Например, повторное списание денег с карты - крайне опасно, а повторная отправка уведомления — обычно безвредно. Поэтому важно проектировать фоновые задачи так, чтобы повторное выполнение не приводило к повреждению данных.

Что сложнее поддерживать в большой системе: код или документацию? Почему? 
Когда речь заходит о том, что сложнее поддерживать - код или документацию - большинство разработчиков сходятся во мнении, что документация намного сложнее. Код постоянно находится «в работе»: его обновляют, тестируют, фиксируют, и любые изменения сразу заметны - приложение либо работает, либо падает. Документация же сама по себе не валится и не сообщает, что она устарела. Поэтому очень легко забыть её обновить. В результате через несколько месяцев документация может уже не соответствовать системе, а несоответствие обнаружится только тогда, когда новый разработчик или пользователь попытается ей воспользоваться.

Какие плюсы и минусы у ручного написания README по сравнению с автогенерацией документации? 
Сравнивая ручное написание README с автогенерацией документации, можно заметить, что оба подхода имеют свои плюсы и минусы. Ручное README позволяет объяснить архитектуру и запуск проекта человеческим языком, дать советы, примеры, особенности. Это делает проект понятным для новичков и облегчает онбординг. Но ручные тексты требуют времени и внимания, и есть риск, что автор забудет их обновить. Автоматически генерируемая документация, такая как Swagger или OpenAPI, всегда соответствует реальному API, так как базируется прямо на коде. Это исключает человеческие ошибки и делает документацию актуальной. Но такие документы сухие, технические и не дают широкого контекста — новичку всё равно будет сложно понять общую картину проекта.

Как документация помогает при онбординге новых разработчиков в команду?
Документация напрямую влияет на онбординг новых разработчиков. Когда человек приходит в проект, ему нужно быстро понять, как устроена система, как её запустить, какие сервисы существуют, как они взаимодействуют и где находится ключевая логика. Хорошая документация позволяет новому разработчику адаптироваться значительно быстрее, самостоятельно поднять проект, изучить архитектуру и приступить к работе без постоянных вопросов к коллегам. Если документации нет или она устарела, онбординг превращается в долгий, мучительный процесс с множеством ошибок и недоразумений.
